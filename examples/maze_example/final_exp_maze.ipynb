{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-watch",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mce_irl_pomdps import parser_pomdp\n",
    "from mce_irl_pomdps import irl_pomdp_solver as irl_solver\n",
    "import numpy as np\n",
    "import stormpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pomdps with different memory size\n",
    "pomdp_r_1 = parser_pomdp.PrismModel(\"maze_stochastic.pm\", counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=1, export=False)\n",
    "pomdp_r_5 = parser_pomdp.PrismModel(\"maze_stochastic.pm\", counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=5, export=False)\n",
    "pomdp_r_10 = parser_pomdp.PrismModel(\"maze_stochastic.pm\", counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=10, export=False)\n",
    "pomdp_r_15 = parser_pomdp.PrismModel(\"maze_stochastic.pm\", counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=15, export=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameter for the trust region\n",
    "irl_solver.trustRegion = {'red' : lambda x : ((x - 1) / 1.5 + 1),\n",
    "                          'aug' : lambda x : min(1.5,(x-1)*1.25+1),\n",
    "                          'lim' : 1+1e-3}\n",
    "# Options for the solver\n",
    "options_opt = irl_solver.OptOptions(mu=1e3, mu_spec=1, maxiter=100, maxiter_weight=100,\n",
    "                      graph_epsilon=0, discount=0.999, verbose=True, verbose_solver=False)\n",
    "# True reward in the POMDP environment\n",
    "weight = { 'poisonous' : 10, 'total_time' : 0.1, 'goal_reach' : 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the solver for different memory size\n",
    "irlPb_1 = irl_solver.IRLSolver(pomdp_r_1, init_trust_region=1.05, max_trust_region=1.5, options=options_opt)\n",
    "irlPb_5 = irl_solver.IRLSolver(pomdp_r_5, init_trust_region=1.05, max_trust_region=1.5, options=options_opt)\n",
    "irlPb_10 = irl_solver.IRLSolver(pomdp_r_10, init_trust_region=1.05, max_trust_region=1.5, options=options_opt)\n",
    "irlPb_15 = irl_solver.IRLSolver(pomdp_r_15, init_trust_region=1.05, max_trust_region=1.5, options=options_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-subsection",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the optimal policy for memory size 1 and save such policy and the associated performances\n",
    "pol_val_grb_1 = irlPb_1.from_reward_to_policy_via_scp(weight, save_info=(20, 'maze_mem1_fwd'))\n",
    "# Get the optimal policy for memory size 1 and save such policy and the associated performances\n",
    "pol_val_grb_5 = irlPb_5.from_reward_to_policy_via_scp(weight, save_info=(20, 'maze_mem5_fwd'))\n",
    "# Get the optimal policy for memory size 1 and save such policy and the associated performances\n",
    "pol_val_grb_10 = irlPb_10.from_reward_to_policy_via_scp(weight, save_info=(20, 'maze_mem10_fwd'))\n",
    "# Get the optimal policy for memory size 1 and save such policy and the associated performances\n",
    "pol_val_grb_15 = irlPb_15.from_reward_to_policy_via_scp(weight, save_info=(20, 'maze_mem15_fwd'))\n",
    "# Get the optimal policy if the agent has full observability\n",
    "pol_val_mdp = irlPb_1.from_reward_to_optimal_policy_mdp_lp(weight, gamma=options_opt.discount, save_info=(-1,'maze_mdp_fwd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Trajectory of different length using the state-based policy from the MDP and observation-based from MDP\n",
    "obs_based = True\n",
    "pol_val_grb_15 = parser_pomdp.correct_policy(pol_val_grb_15)\n",
    "traj_pomdp_mem15_5, _ = pomdp_r_15.simulate_policy(pol_val_grb_15, weight, 5, 300,\n",
    "                                            obs_based=obs_based, stop_at_accepting_state=True)\n",
    "traj_pomdp_mem15_100, _ = pomdp_r_15.simulate_policy(pol_val_grb_15, weight, 100, 300,\n",
    "                                            obs_based=obs_based, stop_at_accepting_state=True)\n",
    "obs_based = False\n",
    "traj_mdp_5, _ = pomdp_r_1.simulate_policy(pol_val_mdp, weight, 5, 300,\n",
    "                                            obs_based=obs_based, stop_at_accepting_state=True)\n",
    "traj_mdp_100, _ = pomdp_r_1.simulate_policy(pol_val_mdp, weight, 100, 300,\n",
    "                                            obs_based=obs_based, stop_at_accepting_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COmpute the feature expectation of the trajectorie\n",
    "feat_pomdp_mem15_5 =irlPb_15.compute_feature_from_trajectory(traj_pomdp_mem15_5)\n",
    "feat_pomdp_mem15_100 =irlPb_15.compute_feature_from_trajectory(traj_pomdp_mem15_100)\n",
    "feat_mdp_5 =irlPb_1.compute_feature_from_trajectory(traj_mdp_5)\n",
    "feat_mdp_100 =irlPb_1.compute_feature_from_trajectory(traj_mdp_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "irl_solver.trustRegion = {'red' : lambda x : ((x - 1) / 1.5 + 1),\n",
    "                          'aug' : lambda x : min(1.5,(x-1)*1.25+1),\n",
    "                          'lim' : 1+1e-4}\n",
    "\n",
    "options_opt = irl_solver.OptOptions(mu=1e3, mu_spec=1e1, maxiter=100, max_update= 3, \n",
    "                                    maxiter_weight=300, rho_weight= 1, verbose_solver=False,\n",
    "                                    graph_epsilon=0, discount=0.999, verbose=False, verbose_weight=True)\n",
    "# Decreasing step size in the gradient updates\n",
    "irl_solver.gradientStepSize = lambda iterVal, diffFeat : 1 / np.power(iterVal+1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-fiber",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learn from the MDP demonstrations on a single memory\n",
    "irlPb_1._options = options_opt\n",
    "_, pol_mdp_mem1_5 = irlPb_1.solve_irl_pomdp_given_traj(feat_mdp_5, save_info=(20, 'maze_mem1_trajsize5mdp_irl'))\n",
    "_, pol_mdp_mem1_100 = irlPb_1.solve_irl_pomdp_given_traj(feat_mdp_100, save_info=(20, 'maze_mem1_trajsize100mdp_irl'))\n",
    "# Learn from the MDP demonstrations on a memory len 5\n",
    "irlPb_5._options = options_opt\n",
    "_, pol_mdp_mem5_5 = irlPb_5.solve_irl_pomdp_given_traj(feat_mdp_5, save_info=(20, 'maze_mem5_trajsize5mdp_irl'))\n",
    "_, pol_mdp_mem5_100 = irlPb_5.solve_irl_pomdp_given_traj(feat_mdp_100, save_info=(20, 'maze_mem5_trajsize100mdp_irl'))\n",
    "# Learn from the MDP demonstrations on a memory len 10\n",
    "irlPb_10._options = options_opt\n",
    "_, pol_mdp_mem10_5 = irlPb_10.solve_irl_pomdp_given_traj(feat_mdp_5, save_info=(20, 'maze_mem10_trajsize5mdp_irl'))\n",
    "_, pol_mdp_mem10_100 = irlPb_10.solve_irl_pomdp_given_traj(feat_mdp_100, save_info=(20, 'maze_mem10_trajsize100mdp_irl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn from the POMDP demonstrations on a single memory\n",
    "irlPb_1._options = options_opt\n",
    "_, pol_pomdp_mem1_5 = irlPb_1.solve_irl_pomdp_given_traj(feat_pomdp_mem15_5, save_info=(20, 'maze_mem1_trajsize5pomdp_irl'))\n",
    "_, pol_pomdp_mem1_100 = irlPb_1.solve_irl_pomdp_given_traj(feat_pomdp_mem15_100, save_info=(20, 'maze_mem1_trajsize100pomdp_irl'))\n",
    "# Learn from the POMDP demonstrations on a memory len 5\n",
    "irlPb_5._options = options_opt\n",
    "_, pol_pomdp_mem5_5 = irlPb_5.solve_irl_pomdp_given_traj(feat_pomdp_mem15_5, save_info=(20, 'maze_mem5_trajsize5pomdp_irl'))\n",
    "_, pol_pomdp_mem5_100 = irlPb_5.solve_irl_pomdp_given_traj(feat_pomdp_mem15_100, save_info=(20, 'maze_mem5_trajsize100pomdp_irl'))\n",
    "# Learn from the POMDP demonstrations on a memory len 10\n",
    "irlPb_10._options = options_opt\n",
    "_, pol_pomdp_mem10_5 = irlPb_10.solve_irl_pomdp_given_traj(feat_pomdp_mem15_5, save_info=(20, 'maze_mem10_trajsize5pomdp_irl'))\n",
    "_, pol_pomdp_mem10_100 = irlPb_10.solve_irl_pomdp_given_traj(feat_pomdp_mem15_100, save_info=(20, 'maze_mem10_trajsize100pomdp_irl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with side information\n",
    "pomdp_r_1_si = parser_pomdp.PrismModel(\"maze_stochastic.pm\",  [\"P=? [F \\\"target\\\"]\"], counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=1, export=False)\n",
    "pomdp_r_5_si = parser_pomdp.PrismModel(\"maze_stochastic.pm\", [\"P=? [F \\\"target\\\"]\"], counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=5, export=False)\n",
    "pomdp_r_10_si = parser_pomdp.PrismModel(\"maze_stochastic.pm\", [\"P=? [F \\\"target\\\"]\"], counter_type=stormpy.pomdp.PomdpMemoryPattern.selective_counter, memory_len=10, export=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_opt = irl_solver.OptOptions(mu=1e3, mu_spec=1e1, maxiter=100, max_update= 3, \n",
    "                                    maxiter_weight=300, rho_weight= 1, verbose_solver=False,\n",
    "                                    graph_epsilon=0, discount=0.999, verbose=False, verbose_weight=True)\n",
    "# Build the solver for different memory size\n",
    "irlPb_1_si = irl_solver.IRLSolver(pomdp_r_1_si, init_trust_region=1.05, sat_thresh=0.9, max_trust_region=1.5, options=options_opt)\n",
    "irlPb_5_si = irl_solver.IRLSolver(pomdp_r_5_si, init_trust_region=1.05, sat_thresh=0.98, max_trust_region=1.5, options=options_opt)\n",
    "irlPb_10_si = irl_solver.IRLSolver(pomdp_r_10_si, init_trust_region=1.05, sat_thresh=0.98, max_trust_region=1.5, options=options_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn from the MDP demonstrations on a single memory\n",
    "irlPb_1_si._options = options_opt\n",
    "_, pol_mdp_mem1_5_si = irlPb_1_si.solve_irl_pomdp_given_traj(feat_mdp_5, save_info=(20, 'maze_mem1_trajsize5mdp_irl_si'))\n",
    "_, pol_mdp_mem1_100_si = irlPb_1_si.solve_irl_pomdp_given_traj(feat_mdp_100, save_info=(20, 'maze_mem1_trajsize100mdp_irl_si'))\n",
    "# Learn from the MDP demonstrations on a memory len 5\n",
    "irlPb_5_si._options = options_opt\n",
    "_, pol_mdp_mem5_5_si = irlPb_5_si.solve_irl_pomdp_given_traj(feat_mdp_5, save_info=(20, 'maze_mem5_trajsize5mdp_irl_si'))\n",
    "_, pol_mdp_mem5_100_si = irlPb_5_si.solve_irl_pomdp_given_traj(feat_mdp_100, save_info=(20, 'maze_mem5_trajsize100mdp_irl_si'))\n",
    "# Learn from the MDP demonstrations on a memory len 10\n",
    "irlPb_10_si._options = options_opt\n",
    "_, pol_mdp_mem10_5_si = irlPb_10_si.solve_irl_pomdp_given_traj(feat_mdp_5, save_info=(20, 'maze_mem10_trajsize5mdp_irl_si'))\n",
    "_, pol_mdp_mem10_100_si = irlPb_10_si.solve_irl_pomdp_given_traj(feat_mdp_100, save_info=(20, 'maze_mem10_trajsize100mdp_irl_si'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn from the POMDP demonstrations on a single memory\n",
    "irlPb_1_si._options = options_opt\n",
    "_, pol_pomdp_mem1_5 = irlPb_1_si.solve_irl_pomdp_given_traj(feat_pomdp_mem15_5, save_info=(20, 'maze_mem1_trajsize5pomdp_irl_si'))\n",
    "_, pol_pomdp_mem1_100 = irlPb_1_si.solve_irl_pomdp_given_traj(feat_pomdp_mem15_100, save_info=(20, 'maze_mem1_trajsize100pomdp_irl_si'))\n",
    "# Learn from the POMDP demonstrations on a memory len 5\n",
    "irlPb_5_si._options = options_opt\n",
    "_, pol_pomdp_mem5_5 = irlPb_5_si.solve_irl_pomdp_given_traj(feat_pomdp_mem15_5, save_info=(20, 'maze_mem5_trajsize5pomdp_irl_si'))\n",
    "_, pol_pomdp_mem5_100 = irlPb_5_si.solve_irl_pomdp_given_traj(feat_pomdp_mem15_100, save_info=(20, 'maze_mem5_trajsize100pomdp_irl_si'))\n",
    "# Learn from the POMDP demonstrations on a memory len 10\n",
    "irlPb_10_si._options = options_opt\n",
    "_, pol_pomdp_mem10_5 = irlPb_10_si.solve_irl_pomdp_given_traj(feat_pomdp_mem15_5, save_info=(20, 'maze_mem10_trajsize5pomdp_irl_si'))\n",
    "_, pol_pomdp_mem10_100 = irlPb_10_si.solve_irl_pomdp_given_traj(feat_pomdp_mem15_100, save_info=(20, 'maze_mem10_trajsize100pomdp_irl_si'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
